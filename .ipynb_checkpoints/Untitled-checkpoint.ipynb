{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class_names = ['l', 'n']\n",
    "states = [9, 9]\n",
    "\n",
    "length = 0\n",
    "for d in class_names:\n",
    "    length += len(os.listdir(\"datatrim/\" + d))\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "\n",
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'n': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "all_labels = {}\n",
    "for cname in class_names:\n",
    "    file_paths = [os.path.join(\"datatrim\", cname, i) for i in os.listdir(os.path.join('datatrim', cname)) if i.endswith('.wav')]\n",
    "    data = [get_mfcc(file_path) for file_path in file_paths]\n",
    "    all_data[cname] = data\n",
    "    all_labels[cname] = [class_names.index(cname) for i in range(len(file_paths))]\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = {'train': {}, 'test': {}}\n",
    "y = {'train': {}, 'test': {}}\n",
    "for cname in class_names:\n",
    "    x_train, x_test, _, y_test = train_test_split(\n",
    "        all_data[cname], all_labels[cname], \n",
    "        test_size = 0.25, \n",
    "        random_state=42\n",
    "    )\n",
    "    X['train'][cname] = x_train\n",
    "    X['test'][cname] = x_test\n",
    "    y['test'][cname] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l 37 13 13\n",
      "n 39 14 14\n"
     ]
    }
   ],
   "source": [
    "for cname in class_names:\n",
    "    print(cname,len(X['train'][cname]), len(X['test'][cname]), len(y['test'][cname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1     -135621.0248             +nan\n",
      "         2     -119555.3012      +16065.7236\n",
      "         3     -118267.8231       +1287.4780\n",
      "         4     -118059.8318        +207.9913\n",
      "         5     -117960.8672         +98.9646\n",
      "         6     -117923.8994         +36.9678\n",
      "         7     -117906.2718         +17.6276\n",
      "         8     -117897.8039          +8.4678\n",
      "         9     -117886.4904         +11.3135\n",
      "        10     -117851.2131         +35.2773\n",
      "        11     -117835.2809         +15.9322\n",
      "        12     -117838.9078          -3.6269\n",
      "         1     -144563.6046             +nan\n",
      "         2     -126638.2679      +17925.3367\n",
      "         3     -125270.2022       +1368.0657\n",
      "         4     -125011.9718        +258.2304\n",
      "         5     -124792.5329        +219.4389\n",
      "         6     -124626.9085        +165.6243\n",
      "         7     -124518.1454        +108.7631\n",
      "         8     -124431.8887         +86.2568\n",
      "         9     -124384.1264         +47.7623\n",
      "        10     -124342.4208         +41.7056\n",
      "        11     -124318.3372         +24.0836\n",
      "        12     -124303.5116         +14.8256\n",
      "        13     -124290.6701         +12.8415\n",
      "        14     -124276.2410         +14.4290\n",
      "        15     -124260.6896         +15.5515\n",
      "        16     -124250.9977          +9.6919\n",
      "        17     -124245.5399          +5.4578\n",
      "        18     -124242.2472          +3.2927\n",
      "        19     -124498.2711        -256.0239\n"
     ]
    }
   ],
   "source": [
    "import hmmlearn.hmm as hmm\n",
    "\n",
    "model = {}\n",
    "for idx, cname in enumerate(class_names):\n",
    "    start_prob = np.full(states[idx], 0.0)\n",
    "    start_prob[0] = 1\n",
    "    \n",
    "    if (cname=='l'):\n",
    "        model[cname] = hmm.GaussianHMM(\n",
    "            n_components=states[idx], \n",
    "            verbose=True, \n",
    "            n_iter=300, \n",
    "            startprob_prior=start_prob, \n",
    "            transmat_prior=np.array([\n",
    "                [0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
    "            ]),\n",
    "            params='stmc',\n",
    "            init_params='mc',\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    if (cname=='n'):\n",
    "        model[cname] = hmm.GaussianHMM(\n",
    "            n_components=states[idx], \n",
    "            verbose=True, \n",
    "            n_iter=300, \n",
    "            startprob_prior=start_prob, \n",
    "            transmat_prior=np.array([\n",
    "                [0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5],\n",
    "                [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ],\n",
    "            ]),\n",
    "            params='stmc',\n",
    "            init_params='mc',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "    model[cname].fit(X=np.vstack(X['train'][cname]), lengths=[x.shape[0] for x in X['train'][cname]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianHMM(init_params='mc', n_components=9, n_iter=300, random_state=42,\n",
      "            startprob_prior=array([1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      "            transmat_prior=array([[0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ]]),\n",
      "            verbose=True)\n",
      "GaussianHMM(init_params='mc', n_components=9, n_iter=300, random_state=42,\n",
      "            startprob_prior=array([1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      "            transmat_prior=array([[0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ]]),\n",
      "            verbose=True)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save model\n",
    "for cname in class_names:\n",
    "    name = f'models\\model_{cname}.pickle'\n",
    "    print(model[cname])\n",
    "    with open(name, 'wb') as file: \n",
    "        pickle.dump(model[cname], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3321.0780409043027, -3551.8825519768475]\n",
      "[-3598.008388383607, -3629.0256626679848]\n",
      "[-3483.446027928627, -3722.2023257690457]\n",
      "[-3180.914977923364, -3209.679604779526]\n",
      "[-2919.224240525048, -3036.4069514583184]\n",
      "[-3004.1852750895455, -3199.1156515301604]\n",
      "[-2824.5525964984713, -3028.4247024097567]\n",
      "[-3327.156134690217, -3451.2998291038803]\n",
      "[-3739.804923762279, -3873.3870776654917]\n",
      "[-3338.272901829514, -3386.414512403117]\n",
      "[-3328.4855508014475, -3430.108590071496]\n",
      "[-2280.152608221956, -2456.5268320782225]\n",
      "[-3045.289058800544, -3232.1105199888675]\n",
      "[-3362.0487063110127, -3089.4850803950603]\n",
      "[-3393.248787937675, -3189.712240026204]\n",
      "[-4358.872877173113, -4205.581058486786]\n",
      "[-3076.4101789410215, -2850.5907283109946]\n",
      "[-2925.587879967438, -2778.761026128627]\n",
      "[-3068.053080101462, -2871.507771631816]\n",
      "[-2935.575642807935, -2727.3151022614707]\n",
      "[-3214.8386274640475, -3092.4862992666917]\n",
      "[-3360.276340644684, -3132.1880122153866]\n",
      "[-3048.127928832758, -2767.523269750298]\n",
      "[-3330.600707026222, -3118.755715020658]\n",
      "[-2898.1746914109326, -2715.69297513905]\n",
      "[-3551.3153576568957, -3461.770115812317]\n",
      "[-3083.2004403116357, -2891.9074296584504]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for cname in class_names:\n",
    "    for mfcc, target in zip(X['test'][cname], y['test'][cname]):\n",
    "        scores = [model[cname].score(mfcc) for cname in class_names]\n",
    "        print(scores)\n",
    "        pred = np.argmax(scores)\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(target)\n",
    "print(y_true)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           l       1.00      1.00      1.00        13\n",
      "           n       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        27\n",
      "   macro avg       1.00      1.00      1.00        27\n",
      "weighted avg       1.00      1.00      1.00        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loadmodels\n",
    "import pickle\n",
    "\n",
    "model = {}\n",
    "for key in class_names:\n",
    "    name = f\"models\\model_{key}.pkl\"\n",
    "    with open(name, 'rb') as file:\n",
    "        model[key] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import messagebox\n",
    "import winsound\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import ffmpeg\n",
    "\n",
    "#Thay đổi threshold dựa vào tạp âm, càng ồn thì threshold càng lớn\n",
    "def detect_leading_silence(sound, silence_threshold=-35.0, chunk_size=10):\n",
    "    '''\n",
    "    sound is a pydub.AudioSegment\n",
    "    silence_threshold in dB\n",
    "    chunk_size in ms\n",
    "\n",
    "    iterate over chunks until you find the first one with sound\n",
    "    '''\n",
    "    trim_ms = 0 # ms\n",
    "\n",
    "    assert chunk_size > 0 # to avoid infinite loop\n",
    "    while sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold and trim_ms < len(sound):\n",
    "        trim_ms += chunk_size\n",
    "\n",
    "    return trim_ms\n",
    "\n",
    "def record():\n",
    "    import pyaudio\n",
    "    import wave\n",
    "    from base64 import b64decode\n",
    "\n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 16000\n",
    "    RECORD_SECONDS = 2\n",
    "    WAVE_OUTPUT_FILENAME = \"record.wav\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=FORMAT,\n",
    "                    channels=CHANNELS,\n",
    "                    rate=RATE,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "def play():    \n",
    "    filename = 'record.wav'\n",
    "    winsound.PlaySound(filename, winsound.SND_FILENAME)\n",
    "    \n",
    "def playtrimmed():    \n",
    "    filename = 'trimmed.wav'\n",
    "    winsound.PlaySound(filename, winsound.SND_FILENAME)\n",
    "\n",
    "def predict():\n",
    "    #Trim silence\n",
    "    sound = AudioSegment.from_file(\"record.wav\", format=\"wav\")\n",
    "\n",
    "    start_trim = detect_leading_silence(sound)\n",
    "    end_trim = detect_leading_silence(sound.reverse())\n",
    "\n",
    "    duration = len(sound)    \n",
    "    \n",
    "    trimmed_sound = sound[start_trim:duration-end_trim]    \n",
    "    trimmed_sound.export(\"trimmed.wav\", format=\"wav\")\n",
    "    \n",
    "    #Predict\n",
    "    record_mfcc = get_mfcc(\"trimmed.wav\")\n",
    "    scores = [model[cname].score(record_mfcc) for cname in class_names]\n",
    "    pred = np.argmax(scores)\n",
    "    messagebox.showinfo(\"result\", class_names[pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "window = tk.Tk()\n",
    "window.geometry(\"300x200\")\n",
    "window.title(\"Speech recognition\")\n",
    "\n",
    "frame0 = tk.Frame(master=window)\n",
    "frame0.pack()\n",
    "\n",
    "frame1 = tk.Frame(master=window)\n",
    "frame1.pack()\n",
    "\n",
    "frame2 = tk.Frame(master=window)\n",
    "frame2.pack()\n",
    "\n",
    "label = tk.Label(master=frame0, text=\"Speech recognition\")\n",
    "label.pack(padx=5, pady=10)\n",
    "\n",
    "btn_record = tk.Button(master=frame1, width=13, height=2, text=\"record\", command=record)\n",
    "btn_record.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "btn_playback = tk.Button(master=frame1, width=13, height=2, text=\"playback\", command=play)\n",
    "btn_playback.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "btn_predict = tk.Button(master=frame2, width=13, height=2, text=\"trim & predict\", command=predict)\n",
    "btn_predict.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "btn_playback = tk.Button(master=frame2, width=13, height=2, text=\"playbacktrimmed\", command=playtrimmed)\n",
    "btn_playback.pack(side=tk.LEFT, padx=5, pady=5)\n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting ./splitAudio/chunk0.wav\n",
      "exporting ./splitAudio/chunk1.wav\n",
      "exporting ./splitAudio/chunk2.wav\n",
      "exporting ./splitAudio/chunk3.wav\n",
      "exporting ./splitAudio/chunk4.wav\n",
      "exporting ./splitAudio/chunk5.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "sound_file = AudioSegment.from_wav(\"data.wav\")\n",
    "audio_chunks = split_on_silence(sound_file, \n",
    "    # must be silent for at least half a second\n",
    "    min_silence_len=50,\n",
    "\n",
    "    # consider it silent if quieter than -16 dBFS\n",
    "    silence_thresh=-16\n",
    ")\n",
    "\n",
    "for i, chunk in enumerate(audio_chunks):\n",
    "\n",
    "    out_file = \"./splitAudio/chunk{0}.wav\".format(i)\n",
    "    print (\"exporting\", out_file)\n",
    "    chunk.export(out_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting ./letter/chunk0.wav\n",
      "exporting ./letter/chunk1.wav\n",
      "exporting ./letter/chunk2.wav\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "myaudio = AudioSegment.from_file(\"./splitAudio/chunk4.wav\" , \"wav\") \n",
    "chunk_length_ms = 200 # pydub calculates in millisec\n",
    "chunks = make_chunks(myaudio, chunk_length_ms)\n",
    "\n",
    "#Export all of the individual chunks as wav files\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk_name = \"./letter/chunk{0}.wav\".format(i)\n",
    "    print (\"exporting\", chunk_name)\n",
    "    chunk.export(chunk_name, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3245.9259397059077, -2953.908661911676]\n",
      "n\n"
     ]
    }
   ],
   "source": [
    "scores = [model[cname].score(get_mfcc(\"./letter/chunk0.wav\")) for cname in class_names]\n",
    "print(scores)\n",
    "pred = np.argmax(scores)\n",
    "print(class_names[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l': GaussianHMM(init_params='mc', n_components=9, n_iter=300, random_state=42,\n",
      "            startprob_prior=array([1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      "            transmat_prior=array([[0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ]]),\n",
      "            verbose=True), 'n': GaussianHMM(init_params='mc', n_components=9, n_iter=300, random_state=42,\n",
      "            startprob_prior=array([1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
      "            transmat_prior=array([[0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. , 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5, 0. ],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.5, 0.5],\n",
      "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 1. ]]),\n",
      "            verbose=True)}\n"
     ]
    }
   ],
   "source": [
    "with open('models.pickle', 'wb') as file: \n",
    "        pickle.dump(model, file)\n",
    "with open('models.pickle', 'rb') as file:\n",
    "        modelss = pickle.load(file)\n",
    "print(modelss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
